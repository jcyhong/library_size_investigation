path_to_data <- "~/Documents/UC Berkeley/spring2020/Researches/librarysize/DATA/11947_himalayas/65668_otu_table.biom"
otu <- otu_table(import_biom(path_to_data))
otu = otu[, which(lapply(1:ncol(otu), function(i) {length(which(otu[, i]>0))})>1)]
otu = otu[, colSums(otu)>=1000]
dim(otu) # 3663 rows and 78 samples (rows)
taxa_are_rows(otu) # taxa are rows (so observations are columns),
otu = as.data.frame(otu)
df_sample <- read.table('~/Documents/UC Berkeley/spring2020/Researches/librarysize/DATA/11947_himalayas/11947_20181001-151811.txt', header=TRUE, sep='\t')
############ GLOBAL VARIABLE ##############
STUDY_ID = 11947
SUMMARY = "himalayas"
WRITE = TRUE
##########################################
show_plot(otu, df_sample, "sample_name", "sex", "TSS", "demographics", TRUE, write = WRITE)
show_plot(otu, df_sample, "sample_name", "sex", "GMPR2", "demographics", TRUE, write = WRITE)
show_plot(otu, df_sample, "sample_name", "sex", "CSS", "demographics", TRUE, write = WRITE)
show_plot(otu, df_sample, "sample_name", "country", "TSS", "demographics", FALSE, write = WRITE)
show_plot(otu, df_sample, "sample_name", "country", "GMPR2", "demographics", FALSE, write = WRITE)
show_plot(otu, df_sample, "sample_name", "country", "CSS", "demographics", FALSE, write = WRITE)
show_plot(otu, df_sample, "sample_name", "population", "TSS", "demographics", FALSE, write = WRITE)
show_plot(otu, df_sample, "sample_name", "population", "GMPR2", "demographics", FALSE, write = WRITE)
show_plot(otu, df_sample, "sample_name", "population", "CSS", "demographics", FALSE, write = WRITE)
show_plot(otu, df_sample[df_sample$population != "Europeans",], "sample_name", "population", "TSS", "demographics", FALSE, write = WRITE)
show_plot(otu, df_sample[df_sample$population != "Europeans",], "sample_name", "population", "GMPR2", "demographics", FALSE, write = WRITE)
show_plot(otu, df_sample[df_sample$population != "Europeans",], "sample_name", "population", "CSS", "demographics", FALSE, write = WRITE)
show_plot(otu, df_sample, "sample_name", "smok", "TSS", "habit", FALSE, write = WRITE)
show_plot(otu, df_sample, "sample_name", "smok", "GMPR2", "habit", FALSE, write = WRITE)
show_plot(otu, df_sample, "sample_name", "smok", "CSS", "habit", FALSE, write = WRITE)
compiled = read.csv("compiled.txt")
compiled
head(compiled)
compiled = read.csv("compiled.txt", sep = " ")
head(compiled)
library(dplyr)
data = read.csv("compiled.txt", sep = " ")
data %>%
f
data %>% group_by_("study_id")
data %>% group_by("study_id")
data %>% group_by(study_id)
n?
?n
?
n
n(unique(data$study_id))
length(unique(data$study_id))
uni = unique(data$study_id)
which(data$study_id == uni[1])
for (i in uni) {}
for (i in uni) {
cat(which(data$study_id == uni[i]))
}
for (i in uni) {
print(which(data$study_id == uni[i]))
}
print(which(data$study_id == uni[1]))
print(which(data$study_id == uni[2]))
for (i in uni) {
print(which(data$study_id == i))
}
for (i in uni) {
print(i, which(data$study_id == i))
}
for (i in uni) {
print(i, which(data$study_id == i))
}
for (i in uni) {
cat(i)
print(which(data$study_id == i))
}
which(data$study_id == "")
which(data$study_id == NA)
which(data$study_id == "NA")
data = read.csv("compiled.txt", sep = " ")
# Number of unique studies:
length(unique(data$study_id))
# Check all indices
for (i in uni) {
cat(i)
print(which(data$study_id == i))
}
read.csv("compiled.txt", sep = "\t")
head(read.csv("compiled.txt", sep = " "))
head(read.csv("compiled.txt", sep = ""))
data = read.csv("compiled.txt", sep = "")
# Number of unique studies:
length(unique(data$study_id))
# Check all indices
for (i in uni) {
cat(i)
print(which(data$study_id == i))
}
library(dplyr)
data = read.csv("compiled.txt", sep = "")
# Number of unique studies:
length(unique(data$study_id))
# Check all indices
for (i in uni) {
cat(i)
print(which(data$study_id == i))
}
for (i in unique(data$study_id)) {
cat(i)
print(which(data$study_id == i))
}
# Check all indices
for (i in unique(data$study_id)) {
cat(i,"\n")
print(which(data$study_id == i))
}
data[data$method =="gmpr2"]
data[data$method =="gmpr2",]
data[data$method =="gmpr2",:]
data[data$method =="gmpr2"]
data[,data$method =="gmpr2"]
data[:,data$method =="gmpr2"]
data[[data$method =="gmpr2"]]
data[data$method =="gmpr2"]
data[data$method =="gmpr2",]
data[data$method =="GMPR2",]
unique(data[data$method =="GMPR2",]$study_id)
# How many distinct groups have GMPR2 only
length(unique(data[data$method =="GMPR2",]$study_id))
# Number of unique studies:
length(unique(data$study_id))
data %>% group_by(method)
data %>% group_by(method) %>% summarise(no = n())
for (i in unique(data$method)) {
cat(i,"\n")
print(which(data$method == i))
}
library(MicrobeDS)
library(dplyr)
library(phyloseq)
library(metagenomeSeq)
library("biomformat")
source("~/Documents/UC Berkeley/spring2020/Researches/librarysize/DATA/functions.R")
path_to_data <- "~/Documents/UC Berkeley/spring2020/Researches/librarysize/DATA/232_forensic/46811_otu_table.biom"
otu <- otu_table(import_biom(path_to_data))
otu = otu[, which(lapply(1:ncol(otu), function(i) {length(which(otu[, i]>0))})>1)]
otu = otu[, colSums(otu)>=1000]
dim(otu) # 2223 taxa (rows) and 115 samples (cols)
taxa_are_rows(otu) # taxa are rows (so observations are columns),
otu = as.data.frame(otu)
df_sample <- read.table('~/Documents/UC Berkeley/spring2020/Researches/librarysize/DATA/232_forensic/232_20170409-171325.txt', header=TRUE, sep='\t')
well_defined <- !grepl('BLANK', df_sample$sample_name)
df_sample <- df_sample %>% filter(well_defined)
############ GLOBAL VARIABLE ##############
STUDY_ID = 232
SUMMARY = "forensic"
WRITE = TRUE
##########################################
show_plot(otu, df_sample, "sample_name", "sample_type", "TSS", "", TRUE, write = WRITE)
show_plot(otu, df_sample, "sample_name", "sample_type", "GMPR2", "", TRUE, write = WRITE)
show_plot(otu, df_sample, "sample_name", "sample_type", "CSS", "", TRUE, write = WRITE)
show_plot(otu, df_sample, "sample_name", "sex", "TSS", "demographics", FALSE, write = WRITE)
show_plot(otu, df_sample, "sample_name", "sex", "GMPR2", "demographics", FALSE, write = WRITE)
show_plot(otu, df_sample, "sample_name", "sex", "CSS", "demographics", FALSE, write = WRITE)
otu
colSums(otu)
library(MicrobeDS)
library(dplyr)
library(phyloseq)
library(metagenomeSeq)
library("biomformat")
source("~/Documents/UC Berkeley/spring2020/Researches/librarysize/DATA/functions.R")
path_to_data <- "~/Documents/UC Berkeley/spring2020/Researches/librarysize/DATA/232_forensic/46811_otu_table.biom"
otu <- otu_table(import_biom(path_to_data))
otu = otu[, which(lapply(1:ncol(otu), function(i) {length(which(otu[, i]>0))})>1)]
#otu = otu[, colSums(otu)>=1000]
dim(otu) # 2223 taxa (rows) and 115 samples (cols)
taxa_are_rows(otu) # taxa are rows (so observations are columns),
otu = as.data.frame(otu)
df_sample <- read.table('~/Documents/UC Berkeley/spring2020/Researches/librarysize/DATA/232_forensic/232_20170409-171325.txt', header=TRUE, sep='\t')
well_defined <- !grepl('BLANK', df_sample$sample_name)
df_sample <- df_sample %>% filter(well_defined)
############ GLOBAL VARIABLE ##############
STUDY_ID = 232
SUMMARY = "forensic"
WRITE = TRUE
##########################################
show_plot(otu, df_sample, "sample_name", "sample_type", "TSS", "", TRUE, write = WRITE)
show_plot(otu, df_sample, "sample_name", "sample_type", "GMPR2", "", TRUE, write = WRITE)
show_plot(otu, df_sample, "sample_name", "sample_type", "CSS", "", TRUE, write = WRITE)
show_plot(otu, df_sample, "sample_name", "sex", "TSS", "demographics", FALSE, write = WRITE)
show_plot(otu, df_sample, "sample_name", "sex", "GMPR2", "demographics", FALSE, write = WRITE)
show_plot(otu, df_sample, "sample_name", "sex", "CSS", "demographics", FALSE, write = WRITE)
colSums(otu)
min(colSums(otu))
data = read.csv("compiled.txt", sep = "")
# How many distinct groups have GMPR2 only: 23
length(unique(data[data$method =="GMPR2",]$study_id))
data %>% group_by(method) %>% summarise(no = n())
data %>% group_by(method) %>% summarise(no = n())
data = read.csv("compiled.txt", sep = "")
data = read.csv("compiled.txt", sep = "")
data %>% group_by(method) %>% summarise(no = n())
# How many distinct groups have GMPR2 only: 23
length(unique(data[data$method =="GMPR2",]$study_id))
data.copy()
data[:]
data[,]
data combined = data[,]
data_combined = data[,]
data_combined[data_combined=="GMPR"] <-"GMPR2"
data_c = data[,]
data_c[data_combined=="GMPR"] <-"GMPR2"
data_c %>% group_by(method) %>% summarise(no = n())
data_c[data_combined$method=="GMPR"] <-"GMPR2"
data_c %>% group_by(method) %>% summarise(no = n())
data_c$method
data_c[data_combined$method=="GMPR"]
?mmutate
?mutate
data_c[data_c$method=="GMPR"]
data_c[data_c=="GMPR"]
data_c = data[,]
data_c[data_c$method=="GMPR"] <-"GMPR2"
a
data_c[data_c$method=="GMPR"]
data_c$method=="GMPR"
data$method
replace(data$method, data$method=="GMPR", "GMPR2"
)
data$method2 = replace(data$method, data$method=="GMPR", "GMPR2")
data_c %>% group_by(method2) %>% summarise(no = n())
data %>% group_by(method2) %>% summarise(no = n())
data %>% group_by(method2) %>% summarise(no = length())
data %>%
group_by(method2) %>%
mutate(per=paste0(round(100*sum(p_val<0.05)/n(),2),'%'))
data = read.csv("compiled.txt", sep = "")
data %>%
group_by(method2) %>%
summarise(per=paste0(round(100*sum(p_val<0.05)/n(),2),'%'))
data = read.csv("compiled.txt", sep = "")
# Combine GMPR and GMPR2
data$method2 = replace(data$method, data$method=="GMPR", "GMPR2")
data %>%
group_by(method2) %>%
summarise(per=paste0(round(100*sum(p_val<0.05)/n(),2),'%'))
data %>%
group_by(method2) %>%
summarise(per=paste0(round(100*sum(p_val<0.05)/108,2),'%'))
data %>%
group_by(method2) %>%
summarise(per=paste0(round(100*sum(p_val<0.05)/n(),2),'%'))
data %>%
group_by(interest) %>%
summarise(per=paste0(round(100*sum(p_val<0.05)/n(),2),'%'))
data %>%
group_by(group) %>%
summarise(per=paste0(round(100*sum(p_val<0.05)/n(),2),'%'))
?summarise
data %>%
group_by(group) %>%
summarise(per=paste0(round(100*sum(p_val<0.05)/n(),2),'%'), sort =T)
data %>%
group_by(group) %>%
summarise(per=paste0(round(100*sum(p_val<0.05)/n(),2),'%'))
data %>%
group_by(category) %>%
summarise(per=paste0(round(100*sum(p_val<0.05)/n(),2),'%'))
data %>%
group_by(category) %>%
summarise(per=paste0(round(sort(100*sum(p_val<0.05)/n()),2),'%'))
# Percentage of large effect size for methods, inyterest, category
data %>%
group_by(method2) %>%
summarise(per=paste0(round(100*sum(effsize>0.8)/n(),2),'%'))
# Percentage of large effect size for methods, inyterest, category
data %>%
group_by(method2) %>%
summarise(per=paste0(round(100*sum(effsize>0.5)/n(),2),'%'))
max(data$effsize)
mean(data$effsize)
data %>%
group_by(interest) %>%
summarise(per=paste0(round(100*sum(p_val<0.05)/n(),2),'%'))
data %>%
group_by(category) %>%
summarise(per=paste0(round(100*sum(p_val<0.05)/n(),2),'%'))
# Percentage of significant p_val for methods, inyterest, category
data %>%
group_by(method2) %>%
summarise(per=paste0(round(100*sum(p_val<0.05)/n(),2),'%'))
# Number of unique studies: 28
length(unique(data$study_id))
data %>%
group_by(interest) %>%
summarise(per=paste0(round(100*sum(p_val<0.05)/n(),2),'%'))
# Percentage of significant p_val for methods, inyterest, category
data %>%
group_by(method2) %>%
summarise(per=paste0(round(100*sum(p_val<0.05)/n(),2),'%'))
data %>%
group_by(category) %>%
summarise(per=paste0(round(100*sum(p_val<0.05)/n(),2),'%'))
library(MicrobeDS)
library(dplyr)
library(phyloseq)
library(metagenomeSeq)
library("biomformat")
source("~/Documents/UC Berkeley/spring2020/Researches/librarysize/DATA/functions.R")
path_to_data <- "~/Documents/UC Berkeley/spring2020/Researches/librarysize/DATA/10333_urbanization/44761_otu_table.biom"
otu <- otu_table(import_biom(path_to_data))
otu = otu[, which(lapply(1:ncol(otu), function(i) {length(which(otu[, i]>0))})>1)]
otu = otu[, colSums(otu)>=1000]
dim(otu) # 28423 rows and 750 samples (rows)
taxa_are_rows(otu) # taxa are rows (so observations are columns),
otu = as.data.frame(otu)
df_sample <- read.table('~/Documents/UC Berkeley/spring2020/Researches/librarysize/DATA/10333_urbanization/10333_20190808-130957.txt', header=TRUE, sep='\t')
well_defined <- !grepl('blank', df_sample$sample_name)
df_sample <- df_sample %>% filter(well_defined)
############ GLOBAL VARIABLE ##############
STUDY_ID = 10333
SUMMARY = "urbanization"
WRITE = F
show_plot(otu, df_sample, "sample_name", "host_body_habitat", "TSS", "body_site", FALSE, write = WRITE)
show_plot(otu, df_sample, "sample_name", "host_body_site", "TSS", "body_site", FALSE, write = WRITE)
data = read.csv("compiled.txt", sep = "")
# Combine GMPR and GMPR2
data$method2 = replace(data$method, data$method=="GMPR", "GMPR2")
# Percentage of significant p_val for methods, inyterest, category
data %>%
group_by(method2) %>%
summarise(per=paste0(round(100*sum(p_val<0.05)/n(),2),'%'))
# How many distinct studies have GMPR2 only: 23
length(unique(data[data$method =="GMPR2",]$study_id))
# Percentage of significant p_val for methods, inyterest, category
data %>%
group_by(method2) %>%
summarise(per=paste0(round(100*sum(p_val<0.05)/n(),2),'%'))
data %>%
group_by(interest) %>%
summarise(per=paste0(round(100*sum(p_val<0.05)/n(),2),'%'))
data %>%
group_by(category) %>%
summarise(per=paste0(round(100*sum(p_val<0.05)/n(),2),'%'))
library(dplyr)
data = read.csv("compiled.txt", sep = "")
# Combine GMPR and GMPR2
data$method2 = replace(data$method, data$method=="GMPR", "GMPR2")
# Number of unique studies: 28
length(unique(data$study_id))
# Check all indices
for (i in unique(data$study_id)) {
cat(i,"\n")
print(which(data$study_id == i))
}
# How many distinct studies have GMPR2 only: 23
length(unique(data[data$method =="GMPR2",]$study_id))
# Percentage of significant p_val for methods, inyterest, category
data %>%
group_by(method2) %>%
summarise(per=paste0(round(100*sum(p_val<0.05)/n(),2),'%'))
data %>%
group_by(interest) %>%
summarise(per=paste0(round(100*sum(p_val<0.05)/n(),2),'%'))
data %>%
group_by(category) %>%
summarise(per=paste0(round(100*sum(p_val<0.05)/n(),2),'%'))
data %>%
group_by(category) %>%
summarise(total_num = n(), per=paste0(round(100*sum(p_val<0.05)/n(),2),'%'))
data %>%
group_by(category) %>%
summarise(total_num = n()/3, per=paste0(round(100*sum(p_val<0.05)/n(),2),'%'))
data %>%
group_by(category) %>%
summarise(num_cate = n()/3, per=paste0(round(100*sum(p_val<0.05)/n(),2),'%'))
data %>%
group_by(category) %>%
summarise(num_group = n()/3, per=paste0(round(100*sum(p_val<0.05)/n(),2),'%'))
# Percentage of significant p_val for methods, inyterest, category
data %>%
group_by(method2) %>%
summarise(num_group = n()/3, per=paste0(round(100*sum(p_val<0.05)/n(),2),'%'))
data %>%
group_by(interest) %>%
summarise(num_group = n()/3, per=paste0(round(100*sum(p_val<0.05)/n(),2),'%'))
# Percentage of significant p_val for methods, inyterest, category
data %>%
group_by(method2) %>%
summarise(num_group = n(), per=paste0(round(100*sum(p_val<0.05)/n(),2),'%'))
data %>%
group_by(interest) %>%
summarise(num_group = n()/3, per=paste0(round(100*sum(p_val<0.05)/n(),2),'%'))
data %>%
group_by(category) %>%
summarise(num_group = n()/3, per=paste0(round(100*sum(p_val<0.05)/n(),2),'%'))
data[data$interest==1]
data[data$interest==1,]
data_int %>%
group_by(method2) %>%
summarise(num_group = n(), per=paste0(round(100*sum(p_val<0.05)/n(),2),'%'))
data_int = data[data$interest==1,]
data_int %>%
group_by(method2) %>%
summarise(num_group = n(), per=paste0(round(100*sum(p_val<0.05)/n(),2),'%'))
# Percentage of significant p_val for methods, inyterest, category
data %>%
group_by(method2) %>%
summarise(num_group = n(), per=paste0(round(100*sum(p_val<0.05)/n(),2),'%'))
data_int %>%
group_by(method2) %>%
summarise(num_group = n(), per=paste0(round(100*sum(p_val<0.05)/n(),2),'%'))
summarize(data)
summary(data)
summary(data)$category
summary(data$category)
data_int %>%
group_by(method2) %>%
summarise(num_group = n(), per=paste0(round(100*sum(p_val<0.05)/n(),2),'%'))
data_int %>%
group_by(method2) %>%
summarise(num_group = n(), per=paste0(round(100*sum(p_val<0.05)/n(),2),'%'))
data_int %>%
group_by(category) %>%
summarise(num_group = n()/3, per=paste0(round(100*sum(p_val<0.05)/n(),2),'%'))
# popular category: demographics, disease, geo_loc
data %>%
group_by(category) %>%
summarise(num_group = n()/3, per=paste0(round(100*sum(p_val<0.05)/n(),2),'%'))
data %>%
group_by(interest) %>%
summarise(num_group = n()/3, per=paste0(round(100*sum(p_val<0.05)/n(),2),'%'))
library(dplyr)
data = read.csv("compiled.txt", sep = "")
# Combine GMPR and GMPR2
data$method2 = replace(data$method, data$method=="GMPR", "GMPR2")
data_int = data[data$interest==1,]
# Number of unique studies: 28
length(unique(data$study_id))
# Percentage of significant p_val for methods, inyterest, category
data %>%
group_by(method2) %>%
summarise(num_group = n(), per=paste0(round(100*sum(p_val<0.05)/n(),2),'%'))
data_int %>%
group_by(method2) %>%
summarise(num_group = n(), per=paste0(round(100*sum(p_val<0.05)/n(),2),'%'))
data %>%
group_by(interest) %>%
summarise(num_group = n()/3, per=paste0(round(100*sum(p_val<0.05)/n(),2),'%'))
# popular category: demographics, disease, geo_loc
data %>%
group_by(category) %>%
summarise(num_group = n()/3, per=paste0(round(100*sum(p_val<0.05)/n(),2),'%'))
library(dplyr)
data = read.csv("compiled.txt", sep = "")
# Combine GMPR and GMPR2
data$method2 = replace(data$method, data$method=="GMPR", "GMPR2")
data_int = data[data$interest==1,]
# popular category: demographics, disease, geo_loc
data %>%
group_by(category) %>%
summarise(num_group = n()/3, per=paste0(round(100*sum(p_val<0.05)/n(),2),'%'))
library(dplyr)
data = read.csv("compiled.txt", sep = "")
# Combine GMPR and GMPR2
data$method2 = replace(data$method, data$method=="GMPR", "GMPR2")
data_int = data[data$interest==1,]
# Percentage of significant p_val for methods, inyterest, category
data %>%
group_by(method2) %>%
summarise(num_group = n(), per=paste0(round(100*sum(p_val<0.05)/n(),2),'%'))
# popular category: demographics, disease, geo_loc
data %>%
group_by(category) %>%
summarise(num_group = n()/3, per=paste0(round(100*sum(p_val<0.05)/n(),2),'%'))
data_int %>%
group_by(category) %>%
summarise(num_group = n()/3, per=paste0(round(100*sum(p_val<0.05)/n(),2),'%'))
# popular category: demographics, disease, geo_loc
data %>%
group_by(category) %>%
summarise(num_group = n()/3, per=paste0(round(100*sum(p_val<0.05)/n(),2),'%'))
data_int %>%
group_by(category) %>%
summarise(num_group = n()/3, per=paste0(round(100*sum(p_val<0.05)/n(),2),'%'))
# Percentage of significant p_val for methods, inyterest, category
data %>%
group_by(method2) %>%
summarise(num_group = n(), per=paste0(round(100*sum(p_val<0.05)/n(),2),'%'))
data_int %>%
group_by(method2) %>%
summarise(num_group = n(), per=paste0(round(100*sum(p_val<0.05)/n(),2),'%'))
data %>%
group_by(interest) %>%
summarise(num_group = n()/3, per=paste0(round(100*sum(p_val<0.05)/n(),2),'%'))
# popular category: demographics, disease, geo_loc
data %>%
group_by(category) %>%
summarise(num_group = n()/3, per=paste0(round(100*sum(p_val<0.05)/n(),2),'%'))
data_int %>%
group_by(category) %>%
summarise(num_group = n()/3, per=paste0(round(100*sum(p_val<0.05)/n(),2),'%'))
data_int[data_int$method=="TSS",] %>%
group_by(category) %>%
summarise(num_group = n()/3, per=paste0(round(100*sum(p_val<0.05)/n(),2),'%'))
data_int[data_int$method=="TSS",] %>%
group_by(category) %>%
summarise(num_group = n(), per=paste0(round(100*sum(p_val<0.05)/n(),2),'%'))
data_int[data_int$method=="CSS",] %>%
group_by(category) %>%
summarise(num_group = n(), per=paste0(round(100*sum(p_val<0.05)/n(),2),'%'))
data_int[data_int$method2=="GMPR",] %>%
group_by(category) %>%
summarise(num_group = n(), per=paste0(round(100*sum(p_val<0.05)/n(),2),'%'))
data_int[data_int$method2=="GMPR2",] %>%
group_by(category) %>%
summarise(num_group = n(), per=paste0(round(100*sum(p_val<0.05)/n(),2),'%'))
